<!DOCTYPE html>
<html lang="">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Eduardo  PÃ©rez Pellitero | publications</title>
<meta name="description" content="Eduardo's personal website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="/assets/jpt_css/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ“·</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://perezpellitero.github.io/">
       <span class="font-weight-bold">Eduardo</span>   PÃ©rez Pellitero
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/openings/">
                job offers
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">List of publications in reversed chronological order.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/arxiv_2022.jpg" alt="project image">
  </td>
  
  </div>

  <div id="CatleyChandar2022" class="col-sm-9">
    
      <div class="title">FlexHDR: Modelling Alignment and Exposure Uncertainties for Flexible HDR Imaging</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://sib1.github.io/" target="_blank" rel="noopener noreferrer">S Catley-Chandar</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://thomas-tanay.github.io/about/" target="_blank" rel="noopener noreferrer">T Tanay</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  L Vandroux,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.cs.bham.ac.uk/~leonarda/" target="_blank" rel="noopener noreferrer">A Leonardis</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.eecs.qmul.ac.uk/~gslabaugh/" target="_blank" rel="noopener noreferrer">G Slabaugh</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>E PÃ©rez-Pellitero</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv:2201.02625 [eess.IV],</em>
      
	  
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2201.03210" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2201.03210" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>High dynamic range (HDR) imaging is of fundamental importance in modern digital photography pipelines and used to produce a high-quality photograph with well exposed regions despite varying illumination across the image. This is typically achieved by merging multiple low dynamic range (LDR) images taken at different exposures. However, over-exposed regions and misalignment errors due to poorly compensated motion result in artefacts such as ghosting. In this paper, we present a new HDR imaging technique that specifically models alignment and exposure uncertainties to produce high quality HDR results. We introduce a strategy that learns to jointly align and assess the alignment and exposure reliability using an HDR-aware, uncertainty-driven attention map that robustly merges the frames into a single high quality HDR image. Further, we introduce a progressive, multi-stage image fusion approach that can flexibly merge any number of LDR images in a permutation-invariant manner. Experimental results show our method can produce better quality HDR images with up to 0.8dB PSNR improvement to the state-of-the-art, and subjective improvements in terms of better detail, colours, and fewer artefacts.</p>
    </div>
    
  </div>
</div>
<br>

</li>
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/aaai_2022.jpg" alt="project image">
  </td>
  
  </div>

  <div id="Conde2022" class="col-sm-9">
    
      <div class="title">Model-Based Image Signal Processors via Learnable Dictionaries</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.linkedin.com/in/drmarcosv/" target="_blank" rel="noopener noreferrer">M V Conde</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://smcdonagh.github.io/" target="_blank" rel="noopener noreferrer">S McDonagh</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.linkedin.com/in/matteo-maggioni-026b4918" target="_blank" rel="noopener noreferrer">M Maggioni</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.cs.bham.ac.uk/~leonarda/" target="_blank" rel="noopener noreferrer">A Leonardis</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>E PÃ©rez-Pellitero</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>AAAI,</em>
      
	  
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2201.03210" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2201.03210" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Digital cameras transform sensor RAW readings into RGB images by means of their Image Signal Processor (ISP). Computational photography tasks such as image denoising and colour constancy are commonly performed in the RAW domain, in part due to the inherent hardware design, but also due to the appealing simplicity of noise statistics that result from the direct sensor readings. Despite this, the availability of RAW images is limited in comparison with the abundance and diversity of available RGB data. Recent approaches have attempted to bridge this gap by estimating the RGB to RAW mapping: handcrafted model-based methods that are interpretable and controllable usually require manual parameter fine-tuning, while end-to-end learnable neural networks require large amounts of training data, at times with complex training procedures, and generally lack interpretability and parametric control.
Towards addressing these existing limitations, we present a novel hybrid model-based and data-driven ISP that builds on canonical ISP operations and is both learnable and interpretable. Our proposed invertible model, capable of bidirectional mapping between RAW and RGB domains, employs end-to-end learning of rich parameter representations, i.e. dictionaries, that are free from direct parametric supervision and additionally enable simple and plausible data augmentation. We evidence the value of our data generation process by extensive experiments under both RAW image reconstruction and RAW image denoising tasks, obtaining state-of-the-art performance in both. Additionally, we show that our ISP can learn meaningful mappings from few data samples, and that denoising models trained with our dictionary-based data augmentation are competitive despite having only few or zero ground-truth labels.</p>
    </div>
    
  </div>
</div>
<br>

</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/cvprw_2021.jpg" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2021" class="col-sm-9">
    
      <div class="title">NTIRE 2021 Challenge on High Dynamic Range Imaging: Dataset, Methods and Results</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://sib1.github.io/" target="_blank" rel="noopener noreferrer">S Catley-Chandar</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://www.cs.bham.ac.uk/~leonarda/" target="_blank" rel="noopener noreferrer">A Leonardis</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and R Timofte
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>CVPR Workshops,</em>
      
	  
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2106.01439" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
      <a href="https://competitions.codalab.org/competitions/28162" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="https://arxiv.org/pdf/2106.01439" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper reviews the first challenge on high-dynamic range (HDR) imaging that was part of the New Trends in Image Restoration and Enhancement (NTIRE) workshop, held in conjunction with CVPR 2021. This manuscript focuses on the newly introduced dataset, the proposed methods and their results. The challenge aims at estimating a HDR image from one or multiple respective low-dynamic range (LDR) observations, which might suffer from under- or over-exposed regions and different sources of noise. The challenge is composed by two tracks: In Track 1 only a single LDR image is provided as input, whereas in Track 2 three differently-exposed LDR images with inter-frame motion are available. In both tracks, the ultimate goal is to achieve the best objective HDR reconstruction in terms of PSNR with respect to a ground-truth image, evaluated both directly and with a canonical tonemapping operation.</p>
    </div>
    
  </div>
</div>
<br>

</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/arxiv_2019.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2019" class="col-sm-9">
    
      <div class="title">Perceptual Video Super Resolution with Enhanced Temporal Consistency</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://msajjadi.com/" target="_blank" rel="noopener noreferrer">M S M Sajjadi</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://ei.is.tuebingen.mpg.de/person/mhirsch" target="_blank" rel="noopener noreferrer">M Hirsch</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.is.mpg.de/person/bs" target="_blank" rel="noopener noreferrer">B SchÃ¶lkopf</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv:1807.07930v2 [cs.CV],</em>
      
	  
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1807.07930v2" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1807.07930v2" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>With the advent of perceptual loss functions, new possibilities in super-resolution have emerged, and we currently have models that successfully generate near-photorealistic high-resolution images from their low-resolution observations. Up to now, however, such approaches have been exclusively limited to single image super-resolution. The application of perceptual loss functions on video processing still entails several challenges, mostly related to the lack of temporal consistency of the generated images, i.e., flickering artifacts. In this work, we present a novel adversarial recurrent network for video upscaling that is able to produce realistic textures in a temporally consistent way. The proposed architecture naturally leverages information from previous frames due to its recurrent architecture, i.e. the input to the generator is composed of the low-resolution image and, additionally, the warped output of the network at the previous step. Together with a video discriminator, we also propose additional loss functions to further reinforce temporal consistency in the generated sequences. The experimental validation of our algorithm shows the effectiveness of our approach which obtains images with high perceptual quality and improved temporal consistency.</p>
    </div>
    
  </div>
</div>
<br>

</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/pirm_2018.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2018" class="col-sm-9">
    
      <div class="title">Photorealistic Video Super Resolution</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://msajjadi.com/" target="_blank" rel="noopener noreferrer">M S M Sajjadi</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://ei.is.tuebingen.mpg.de/person/mhirsch" target="_blank" rel="noopener noreferrer">M Hirsch</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.is.mpg.de/person/bs" target="_blank" rel="noopener noreferrer">B SchÃ¶lkopf</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ECCV Workshops (PIRM),</em>
      
	  
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1807.07930v1" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1807.07930v1" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this work, we present a novel adversarial recurrent network for video upscaling that is able to produce realistic textures in a temporally consistent way. The proposed architecture naturally leverages information from previous frames due to its recurrent architecture, i.e. the input to the generator is composed of the low-resolution image and, additionally, the warped output of the network at the previous step.</p>
    </div>
    
  </div>
</div>
<br>

</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/dissertation.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2017" class="col-sm-9">
    
      <div class="title">Manifold Learning for Super Resolution</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Eduardo PÃ©rez-Pellitero</em>
            
          
        
      </div>

      <div class="periodical">
      
	  
        PhD Dissertation<br>Leibniz UniversitÃ¤t Hannover,
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
      <a href="https://www.vdi-nachrichten.com/shop/manifold-learning-for-super-resolution/" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/PerezPellitero_PhDdiss.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The development pace of high-resolution displays has been so fast in the recent years that many images acquired with low-end capture devices are already outdated or will be shortly in time. Super Resolution is central to match the resolution of the already existing image content to that of current and future high resolution displays and applications. This dissertation is focused on learning how to upscale images from the statistics of natural images.</p>
    </div>
    
  </div>
</div>
<br>

</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography">
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/cvpr_2016.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2016a" class="col-sm-9">
    
      <div class="title">PSyCo: Manifold Span Reduction for Super Resolution</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://imatge.upc.edu/web/people/javier-ruiz-hidalgo" target="_blank" rel="noopener noreferrer">J Ruiz-Hidalgo</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.tnt.uni-hannover.de/staff/rosenhahn/" target="_blank" rel="noopener noreferrer">B Rosenhahn</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>CVPR,</em>
      
	  
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/PerezPellitero2016cvpr.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="/coming-soon/" class="btn btn-sm z-depth-1" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper we present a novel regression-based SR algorithm that benefits from an extended knowledge of the structure of both manifolds. We propose a transform that collapses the 16 variations induced from the dihedral group of transforms (i.e. rotations, vertical and horizontal reflections) and antipodality (i.e. diametrically opposed points in the unitary sphere) into a single primitive. The key idea of our transform is to study the different dihedral elements as a group of symmetries within the high-dimensional manifold. The experimental validation of our algorithm shows the effectiveness of our approach, which obtains competitive quality with a dictionary of as little as 32 atoms (reducing other methodsâ€™ dictionaries by at least a factor of 32) and further pushing the state-of-the-art with a 1024 atoms dictionary.</p>
    </div>
    
  </div>
</div>
<br>

</li>
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/tip_2016.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2016b" class="col-sm-9">
    
      <div class="title">Antipodally Invariant Metrics For Fast Regression-based Super-Resolution</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://imatge.upc.edu/web/people/javier-ruiz-hidalgo" target="_blank" rel="noopener noreferrer">J Ruiz-Hidalgo</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.tnt.uni-hannover.de/staff/rosenhahn/" target="_blank" rel="noopener noreferrer">B Rosenhahn</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Trans. Image Processing, </em>
      
	  
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/7445242" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
      <a href="/coming-soon/" class="btn btn-sm z-depth-1" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper we present a very fast regression-based algorithm which builds on densely populated anchored neighborhoods and sublinear search structures. Even though we validate the benefits of using antipodally invariant metrics, most of the binary splits use Euclidean distance, which does not handle antipodes optimally. In order to benefit from both worlds, we propose a simple yet effective Antipodally Invariant Transform (AIT) that can be easily included in the Euclidean distance calculation. We modify the original Spherical Hashing algorithm with this metric in our Antipodally Invariant Spherical Hashing scheme, obtaining the same performance as a pure antipodally invariant metric. We round up our contributions with a novel feature transform that obtains a better coarse approximation of the input image thanks to Iterative Back Projection.</p>
    </div>
    
  </div>
</div>
<br>

</li>
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/wacv_2016.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2016c" class="col-sm-9">
    
      <div class="title">Half Hypersphere Confinement for Piecewise Linear Regression</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://imatge.upc.edu/web/people/javier-ruiz-hidalgo" target="_blank" rel="noopener noreferrer">J Ruiz-Hidalgo</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.tnt.uni-hannover.de/staff/rosenhahn/" target="_blank" rel="noopener noreferrer">B Rosenhahn</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>WACV, </em>
      
	  
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/PerezPellitero2016wacv.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="/coming-soon/" class="btn btn-sm z-depth-1" role="button" target="_blank">Code</a>
    
    
      
      <a href="/assets/pdf/Poster_PerezPellitero2016Wacv.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper we study the characteristics of the metrics best suited for the piecewise regression algorithms, in which comparisons are usually made between normalized vectors that lie on the unitary hypersphere. Even though Euclidean distance has been widely used for this purpose, it is suboptimal since it does not handle antipodal points (i.e. diametrically opposite points) properly. Therefore, we propose the usage of antipodally invariant metrics and introduce the Half Hypersphere Confinement (HHC), a fast alternative to Multidimensional Scaling (MDS) that allows to map antipodally invariant distances in the Euclidean space with very little approximation error. The performance of our method, which we named HHC Regression (HHCR), applied to Super-Resolution (SR) improves both in quality (PSNR) and it is faster than any other state-of-the-art method. Additionally, under an application-agnostic interpretation of our regression framework, we also test our algorithm for denoising and depth upscaling with promising results.</p>
    </div>
    
  </div>
</div>
<br>

</li>
</ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography">
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/iccv_2015.png" alt="project image">
  </td>
  
  </div>

  <div id="Salvador2015" class="col-sm-9">
    
      <div class="title">Naive Bayes Super-Resolution Forest</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>E PÃ©rez-Pellitero</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICCV, </em>
      
	  
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Salvador_Naive_Bayes_Super-Resolution_ICCV_2015_paper.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
      <a href="https://jordisalvador-image.blogspot.com/2015/08/iccv-2015.html" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents a fast, high-performance method for super resolution with external learning. The first contribution leading to the excellent performance is a bimodal tree for clustering, which successfully exploits the antipodal invariance of the coarse-to-high-res mapping of natural image patches and provides scalability to finer partitions of the underlying coarse patch space. During training an ensemble of such bimodal trees is computed, providing different linearizations of the mapping. The second and main contribution is a fast inference algorithm, which selects the most suitable mapping function within the tree ensemble for each patch by adopting a Local Naive Bayes formulation. The resulting method is beyond one order of magnitude faster and performs objectively and subjectively better than the current state of the art.</p>
    </div>
    
  </div>
</div>
<br>

</li>
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/icce_2015.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2015" class="col-sm-9">
    
      <div class="title">Accelerating Super-Resolution for 4K Upscaling</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://imatge.upc.edu/web/people/javier-ruiz-hidalgo" target="_blank" rel="noopener noreferrer">J Ruiz-Hidalgo</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.tnt.uni-hannover.de/staff/rosenhahn/" target="_blank" rel="noopener noreferrer">B Rosenhahn</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICCE,</em>
      
	  
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/PerezPellitero2015icce.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents a fast Super-Resolution (SR) algorithm based on a selective patch processing. Motivated by the observation that some regions of images are smooth and unfocused and can be properly upscaled with fast interpolation methods, we locally estimate the probability of performing a degradation-free upscaling. Our proposed framework explores the usage of supervised machine learning techniques and tackles the problem using binary boosted tree classifiers.</p>
    </div>
    
  </div>
</div>
<br>

</li>
</ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography">
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/accv_2014.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2014" class="col-sm-9">
    
      <div class="title">Fast Super-Resolution via Dense Local Training and Inverse Regressor Search</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  I Torres-Xirau,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://imatge.upc.edu/web/people/javier-ruiz-hidalgo" target="_blank" rel="noopener noreferrer">J Ruiz-Hidalgo</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.tnt.uni-hannover.de/staff/rosenhahn/" target="_blank" rel="noopener noreferrer">B Rosenhahn</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACCV, </em>
      
	  
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/PerezPellitero2014accv.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Under the locally linear embedding assumption, SR can be properly modeled by a set of linear regressors distributed across the manifold. In this paper we propose a fast inverse-search approach for regression-based SR. Instead of performing a search from the image to the dictionary of regressors, the search is done inversely from the regressorsâ€™ dictionary to the image patches. Additionally, we propose an improved training scheme for SR linear regressors which improves perceived and objective quality. By merging both contributions we improve both speed and quality compared to the state-of-the-art.</p>
    </div>
    
  </div>
</div>
<br>

</li>
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/accv2_2014.png" alt="project image">
  </td>
  
  </div>

  <div id="Torres2014" class="col-sm-9">
    
      <div class="title">Fast Approximate Nearest-Neighbor Field by Cascaded Spherical Hashing</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  I Torres-Xirau,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>E PÃ©rez-Pellitero</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACCV,</em>
      
	  
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/TorresXirau2014accv.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present an efficient and fast algorithm for computing approximate nearest neighbor fields between two images. Our method builds on the concept of Coherency-Sensitive Hashing (CSH), but uses a recent hashing scheme, Spherical Hashing (SpH), which is known to be better adapted to the nearest-neighbor problem for natural images. Cascaded Spherical Hashing concatenates different configurations of SpH to build larger Hash Tables with less elements in each bin to achieve higher selectivity. Our method amply outperforms existing techniques like PatchMatch and CSH, and the experimental results show that our algorithm is faster and more accurate than existing methods.</p>
    </div>
    
  </div>
</div>
<br>

</li>
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/icip_2014.png" alt="project image">
  </td>
  
  </div>

  <div id="Salvador2014Icip" class="col-sm-9">
    
      <div class="title">Robust Single-Image Super-Resolution using Cross-Scale Self-Similarity</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and A Kochale
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICIP, </em>
      
	  
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/7025428" class="btn btn-sm z-depth-1" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present a noise-aware single-image super-resolution (SISR) algorithm, which automatically cancels additive noise while adding detail learned from lower-resolution scales. In contrast with most SI-SR techniques, we do not assume the input image to be a clean source of examples. Instead, we adapt the recent and efficient in-place cross-scale self-similarity prior for both learning fine detail examples and reducing image noise. The experimental results show a promising performance, despite the relatively simple algorithm. Both objective evaluations and subjective validations show clear quality improvements when upscaling noisy images.</p>
    </div>
    
  </div>
</div>
<br>

</li>
<li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/eusipco_2014.png" alt="project image">
  </td>
  
  </div>

  <div id="Bosch2014" class="col-sm-9">
    
      <div class="title">An Epipolar-Constrained Prior for Efficient Search in Multi-View Scenarios</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  I Bosch,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://imatge.upc.edu/web/people/javier-ruiz-hidalgo" target="_blank" rel="noopener noreferrer">J Ruiz-Hidalgo</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>EUSIPCO, </em>
      
	  
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/Bosch2014Eusipco.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper we propose a novel framework for fast exploitation of multi-view cues with applicability in different image processing problems. An epipolar-constrained prior is presented, onto which a random search algorithm is proposed to find good matches among the different views of the same scene. This algorithm includes a generalization of the local coherency in 2D images for multi-view wide-baseline cases. Experimental results show that the geometrical constraint allows a faster initial convergence when finding good matches.</p>
    </div>
    
  </div>
</div>
<br>

</li>
</ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li>
<style>
img{
	border: 1px solid #ddd;
	border-radius: 4px;
	width:100%;
}
</style>
<div class="row">
  <div class="col-sm-3">
  
  
  
  <td style="padding:0.0%;vertical-align:top;min-width:auto">
              <img src="/assets/img/bmvc_2013.png" alt="project image">
  </td>
  
  </div>

  <div id="PerezPellitero2013" class="col-sm-9">
    
      <div class="title">Bayesian region selection for adaptive dictionary-based Super-Resolution</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>E PÃ©rez-Pellitero</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jordisalvador-image.blogspot.com/" target="_blank" rel="noopener noreferrer">J Salvador</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://imatge.upc.edu/web/people/javier-ruiz-hidalgo" target="_blank" rel="noopener noreferrer">J Ruiz-Hidalgo</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.tnt.uni-hannover.de/staff/rosenhahn/" target="_blank" rel="noopener noreferrer">B Rosenhahn</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>BMVC, </em>
      
	  
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-1" role="button">Abs</a>
    
    
    
      <a href="/coming-soon/" class="btn btn-sm z-depth-1" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/PerezPellitero2013bmvc.pdf" class="btn btn-sm z-depth-1" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents a novel sparse SR method, which focuses in adaptively selecting the optimal patches for the dictionary training. The method divides the training images into sub-image regions of sizes that preserve texture consistency. The best-representing region for each input LR patch is found through a Bayesian selection stage. In this selection process, SIFT descriptors are extracted densely from both input LR patches and regions and a local NBNN approach is used in order to efficiently handle the high number of different regions in the training dataset.</p>
    </div>
    
  </div>
</div>
<br>

</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    Â© Copyright 2022 Eduardo  PÃ©rez Pellitero.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
